{"nbformat_minor": 1, "cells": [{"execution_count": 23, "cell_type": "code", "source": "from azureml import Workspace\n\nws = Workspace()\nds = ws.datasets['autos.csv']\ndf = ds.to_dataframe()", "outputs": [], "metadata": {}}, {"execution_count": 24, "cell_type": "code", "source": "df.head()", "outputs": [{"execution_count": 24, "output_type": "execute_result", "data": {"text/plain": "   symboling  normalized-losses  make-id fuel-type aspiration num-of-doors  \\\n0          3                NaN        1       gas        std          two   \n1          3                NaN        1       gas        std          two   \n2          1                NaN        1       gas        std          two   \n3          2              164.0        2       gas        std         four   \n4          2              164.0        2       gas        std         four   \n\n    body-style drive-wheels engine-location  wheel-base   ...     engine-size  \\\n0  convertible          rwd           front        88.6   ...             130   \n1  convertible          rwd           front        88.6   ...             130   \n2    hatchback          rwd           front        94.5   ...             152   \n3        sedan          fwd           front        99.8   ...             109   \n4        sedan          4wd           front        99.4   ...             136   \n\n   fuel-system  bore  stroke compression-ratio horsepower  peak-rpm city-mpg  \\\n0         mpfi  3.47    2.68               9.0      111.0    5000.0       21   \n1         mpfi  3.47    2.68               9.0      111.0    5000.0       21   \n2         mpfi  2.68    3.47               9.0      154.0    5000.0       19   \n3         mpfi  3.19    3.40              10.0      102.0    5500.0       24   \n4         mpfi  3.19    3.40               8.0      115.0    5500.0       18   \n\n   highway-mpg    price  \n0           27  13495.0  \n1           27  16500.0  \n2           26  16500.0  \n3           30  13950.0  \n4           22  17450.0  \n\n[5 rows x 26 columns]", "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>symboling<\/th>\n      <th>normalized-losses<\/th>\n      <th>make-id<\/th>\n      <th>fuel-type<\/th>\n      <th>aspiration<\/th>\n      <th>num-of-doors<\/th>\n      <th>body-style<\/th>\n      <th>drive-wheels<\/th>\n      <th>engine-location<\/th>\n      <th>wheel-base<\/th>\n      <th>...<\/th>\n      <th>engine-size<\/th>\n      <th>fuel-system<\/th>\n      <th>bore<\/th>\n      <th>stroke<\/th>\n      <th>compression-ratio<\/th>\n      <th>horsepower<\/th>\n      <th>peak-rpm<\/th>\n      <th>city-mpg<\/th>\n      <th>highway-mpg<\/th>\n      <th>price<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>3<\/td>\n      <td>NaN<\/td>\n      <td>1<\/td>\n      <td>gas<\/td>\n      <td>std<\/td>\n      <td>two<\/td>\n      <td>convertible<\/td>\n      <td>rwd<\/td>\n      <td>front<\/td>\n      <td>88.6<\/td>\n      <td>...<\/td>\n      <td>130<\/td>\n      <td>mpfi<\/td>\n      <td>3.47<\/td>\n      <td>2.68<\/td>\n      <td>9.0<\/td>\n      <td>111.0<\/td>\n      <td>5000.0<\/td>\n      <td>21<\/td>\n      <td>27<\/td>\n      <td>13495.0<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>3<\/td>\n      <td>NaN<\/td>\n      <td>1<\/td>\n      <td>gas<\/td>\n      <td>std<\/td>\n      <td>two<\/td>\n      <td>convertible<\/td>\n      <td>rwd<\/td>\n      <td>front<\/td>\n      <td>88.6<\/td>\n      <td>...<\/td>\n      <td>130<\/td>\n      <td>mpfi<\/td>\n      <td>3.47<\/td>\n      <td>2.68<\/td>\n      <td>9.0<\/td>\n      <td>111.0<\/td>\n      <td>5000.0<\/td>\n      <td>21<\/td>\n      <td>27<\/td>\n      <td>16500.0<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>1<\/td>\n      <td>NaN<\/td>\n      <td>1<\/td>\n      <td>gas<\/td>\n      <td>std<\/td>\n      <td>two<\/td>\n      <td>hatchback<\/td>\n      <td>rwd<\/td>\n      <td>front<\/td>\n      <td>94.5<\/td>\n      <td>...<\/td>\n      <td>152<\/td>\n      <td>mpfi<\/td>\n      <td>2.68<\/td>\n      <td>3.47<\/td>\n      <td>9.0<\/td>\n      <td>154.0<\/td>\n      <td>5000.0<\/td>\n      <td>19<\/td>\n      <td>26<\/td>\n      <td>16500.0<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>2<\/td>\n      <td>164.0<\/td>\n      <td>2<\/td>\n      <td>gas<\/td>\n      <td>std<\/td>\n      <td>four<\/td>\n      <td>sedan<\/td>\n      <td>fwd<\/td>\n      <td>front<\/td>\n      <td>99.8<\/td>\n      <td>...<\/td>\n      <td>109<\/td>\n      <td>mpfi<\/td>\n      <td>3.19<\/td>\n      <td>3.40<\/td>\n      <td>10.0<\/td>\n      <td>102.0<\/td>\n      <td>5500.0<\/td>\n      <td>24<\/td>\n      <td>30<\/td>\n      <td>13950.0<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>2<\/td>\n      <td>164.0<\/td>\n      <td>2<\/td>\n      <td>gas<\/td>\n      <td>std<\/td>\n      <td>four<\/td>\n      <td>sedan<\/td>\n      <td>4wd<\/td>\n      <td>front<\/td>\n      <td>99.4<\/td>\n      <td>...<\/td>\n      <td>136<\/td>\n      <td>mpfi<\/td>\n      <td>3.19<\/td>\n      <td>3.40<\/td>\n      <td>8.0<\/td>\n      <td>115.0<\/td>\n      <td>5500.0<\/td>\n      <td>18<\/td>\n      <td>22<\/td>\n      <td>17450.0<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n<p>5 rows \u00c3\u0097 26 columns<\/p>\n<\/div>"}, "metadata": {}}], "metadata": {}}, {"source": "# Solving Autos Dataset with Sklearn in Jupyter Notebooks\n\nA lovely aspects of Notebooks is that you can use Markdown cells to explain what the code is doing rather than code comments. There are several benefits to doing so:\n\n<ul>\n<li>Markdown allows for richer text formatting, like <em>italics<\/em>, <strong>bold<\/strong>, <code>inline code<\/code>, hyperlinks, and headers.<\/li>\n<li>Markdown cells automatically word wrap whereas code cells do not. Code comments typically use explicit line breaks for formatting, but that's not necessary in Markdown.<\/li>\n<li>Using Markdown cells makes it easier to run the Notebook as a slide show.<\/li>\n<li>Markdown cells help you remove lengthy comments from the code, making the code easier to scan.<\/li>\n<\/ul>", "cell_type": "markdown", "metadata": {}}, {"source": "## Install packages using pip or conda\nBecause the code in your notebook likely uses some Python packages, you need to make sure the Notebook environment contains those packages. You can do this directly within the notebook in a code block that contains the appropriate pip or conda commands prefixed by !:\n\n```\n!pip install  \n```\n\nThis present notebook requires numpy, matplotlib, pandas, and sklearn. Because these packages are already included in Azure Notebooks, the following commands are commented out but are included to clearly note the dependencies.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 2, "cell_type": "code", "source": "!pip install numpy\n!pip install matplotlib\n!pip install pandas\n!pip install sklearn", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Requirement already satisfied: numpy in /home/nbuser/anaconda3_23/lib/python3.4/site-packages\n\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: matplotlib in /home/nbuser/anaconda3_23/lib/python3.4/site-packages\nRequirement already satisfied: numpy>=1.6 in /home/nbuser/anaconda3_23/lib/python3.4/site-packages (from matplotlib)\nRequirement already satisfied: python-dateutil in /home/nbuser/anaconda3_23/lib/python3.4/site-packages (from matplotlib)\nRequirement already satisfied: pytz in /home/nbuser/anaconda3_23/lib/python3.4/site-packages (from matplotlib)\nRequirement already satisfied: cycler in /home/nbuser/anaconda3_23/lib/python3.4/site-packages (from matplotlib)\nRequirement already satisfied: pyparsing!=2.0.4,>=1.5.6 in /home/nbuser/anaconda3_23/lib/python3.4/site-packages (from matplotlib)\nRequirement already satisfied: six>=1.5 in /home/nbuser/anaconda3_23/lib/python3.4/site-packages (from python-dateutil->matplotlib)\n\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: pandas in /home/nbuser/anaconda3_23/lib/python3.4/site-packages\nRequirement already satisfied: python-dateutil>=2 in /home/nbuser/anaconda3_23/lib/python3.4/site-packages (from pandas)\nRequirement already satisfied: pytz>=2011k in /home/nbuser/anaconda3_23/lib/python3.4/site-packages (from pandas)\nRequirement already satisfied: numpy>=1.7.0 in /home/nbuser/anaconda3_23/lib/python3.4/site-packages (from pandas)\nRequirement already satisfied: six>=1.5 in /home/nbuser/anaconda3_23/lib/python3.4/site-packages (from python-dateutil>=2->pandas)\n\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\nCollecting sklearn\n  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\nRequirement already satisfied: scikit-learn in /home/nbuser/anaconda3_23/lib/python3.4/site-packages (from sklearn)\nBuilding wheels for collected packages: sklearn\n  Running setup.py bdist_wheel for sklearn ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\nSuccessfully built sklearn\nInstalling collected packages: sklearn\nSuccessfully installed sklearn-0.0\n\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"}], "metadata": {}}, {"source": "In this example we're using numpy, pandas, and matplotlib. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": 25, "cell_type": "code", "source": "import numpy as np\nimport pandas as pd", "outputs": [], "metadata": {}}, {"execution_count": 30, "cell_type": "code", "source": "X = df.drop('price', axis=1)\ny = df['price']", "outputs": [], "metadata": {}}, {"source": "Next, split the dataset into a Training set (2/3rds) and Test set (1/3rd). We don't need to do any feature scaling because there is only one column of independent variables, and libraries typically do scaling for you.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 31, "cell_type": "code", "source": "from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)", "outputs": [], "metadata": {}}, {"source": "## Fit the data to the training set\n\"Fitting\" the data to a training set means making the line that describes the relationship between the independent and the dependent variables. Fitting the data means plotting all the points in the training set, then drawing the best-fit line through that data.\n\nThe regressor's fit method here creates the line, which algebraically is of the form y = x*b1 + b0, where b1 is the coefficient or slope of the line (which you can get to through regressor.coef_), and b0 is the intercept of the line at x=0 (which you can get to through regressor.intercept).", "cell_type": "markdown", "metadata": {}}, {"execution_count": 103, "cell_type": "code", "source": "from sklearn.linear_model import LinearRegression\n\nregressor = LinearRegression()    # This object is the regressor, that does the regression\nregressor.fit(X_train, y_train)   # Provide training data so the machine can learn to predict using a learned model.", "outputs": [{"execution_count": 103, "output_type": "execute_result", "data": {"text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"}, "metadata": {}}], "metadata": {}}, {"source": "## Dit it work?\n\nOf course no! Life is hard. Linear regression can't handle strings!", "cell_type": "markdown", "metadata": {}}, {"source": "## Dit it work? (try 2)\n\nOf course no! Life is hard. Linear regression can't handle missing values!\n\n<img src='https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/03/How-to-Handle-Missing-Values-with-Python.jpg' />", "cell_type": "markdown", "metadata": {}}, {"source": "## Did it work? (try 3)\n\nYeap! Let's try to use our model. \n\n## Predict the results\nWith the regressor in hand, we can predict the test set results using its predict method. That method takes a vector of independent variables for which you want predictions.\n\nBecause the regressor is fit to the data by virtue of coef_ and intercept_ and coef_, a prediction is the result of coef_ * x + intercept_. (Indeed, predict(0) returns intercept_ and predict(1) returns intercept_ + coef_.)\n\nIn the code, the y_test matrix (from when we split the set) contains the real observations. y_pred assigned here contains the predictions for the same X_test inputs. It's not expected that the test or training points exactly fit the regression; the regression is trying to find the model that we can use to make predictions with new observations of the independent variables.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 105, "cell_type": "code", "source": "y_pred = regressor.predict(X_test)\nprint(y_pred)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[ 10056.29912166   8018.70911357   6790.46282267   8279.28060009\n  10151.96697477   6784.57558414  16791.1603156   17381.60255689\n   7512.75273163   6713.41369343   8988.49361003   7787.21532477\n  13982.15671974  18020.91304936  15055.91295732  13093.5517696\n  20281.60696508  10844.20982215   3701.15495557   7245.26640824\n   7283.47321733   7237.39328578  13887.10936938   6181.24970911\n   6811.40003444   9668.23787983   8353.81592633  17375.58013654\n   5400.80743904  19999.23248481   6990.58111126   8590.93616396\n  10415.52146723  26053.22000726  11724.65361727  14631.75684384\n  18049.59326559   9772.36681982   7315.86287716  19447.19660953\n   6457.60938984   6927.78786544  13318.94945659   6868.034466\n  17171.88348642  11990.87950167  13062.0911398   16468.10608007\n  15354.48083444   7626.22826924   7557.28599222  19999.23248481\n  10510.63062495  15247.25950487   7408.55931931   8279.43309828\n  16663.316801  ]\n"}], "metadata": {}}, {"source": "It's interesting to think that all the \"predictions\" we use in daily life, like weather forecasts, are just regression models of some sort working with various data sets. Those models are much more complicated than what's shown here, but the idea is the same.\n\nKnowing how predictions work help us understand that the actual observations we would collect in the moment will always be somewhat off from the predictions: the predictions fit exactly to the model, whereas the observations typically won't.\n\nOf course, such systems feed new observations back into the dataset to continually improve the model, meaning that predictions should get more accurate over time.\n\nThe challenge is determining what data to actually use. For example, with weather, how far back in time do you go? How have weather patterns been changing decade by decade? In any case, something like weather predictions will be doing things hour by hour, day by day, for things like temperature, precipitation, winds, cloud cover, etc. Radar and other observations are of course fed into the model and the predictions are reduced to mathematics.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 107, "cell_type": "code", "source": "from sklearn.metrics import r2_score\n\nr2_score(y_test, y_pred) ", "outputs": [{"execution_count": 107, "output_type": "execute_result", "data": {"text/plain": "0.8139354578291087"}, "metadata": {}}], "metadata": {}}, {"source": "## Handling string features\n\nThe method dtypes will list all the features along with their corresponding types. Note that anything listed as Object is an string", "cell_type": "markdown", "metadata": {}}, {"execution_count": 12, "cell_type": "code", "source": "df.dtypes", "outputs": [{"execution_count": 12, "output_type": "execute_result", "data": {"text/plain": "symboling              int64\nnormalized-losses    float64\nmake-id                int64\nfuel-type             object\naspiration            object\nnum-of-doors          object\nbody-style            object\ndrive-wheels          object\nengine-location       object\nwheel-base           float64\nlength               float64\nwidth                float64\nheight               float64\ncurb-weight            int64\nengine-type           object\nnum-of-cylinders      object\nengine-size            int64\nfuel-system           object\nbore                 float64\nstroke               float64\ncompression-ratio    float64\nhorsepower           float64\npeak-rpm             float64\ncity-mpg               int64\nhighway-mpg            int64\nprice                float64\ndtype: object"}, "metadata": {}}], "metadata": {}}, {"source": "Pandas has a helpful select_dtypes function which we can use to build a new dataframe containing only the object columns.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 26, "cell_type": "code", "source": "obj_df = df.select_dtypes(include=['object']).copy()\nobj_df.head()", "outputs": [{"execution_count": 26, "output_type": "execute_result", "data": {"text/plain": "  fuel-type aspiration num-of-doors   body-style drive-wheels engine-location  \\\n0       gas        std          two  convertible          rwd           front   \n1       gas        std          two  convertible          rwd           front   \n2       gas        std          two    hatchback          rwd           front   \n3       gas        std         four        sedan          fwd           front   \n4       gas        std         four        sedan          4wd           front   \n\n  engine-type num-of-cylinders fuel-system  \n0        dohc             four        mpfi  \n1        dohc             four        mpfi  \n2        ohcv              six        mpfi  \n3         ohc             four        mpfi  \n4         ohc             five        mpfi  ", "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>fuel-type<\/th>\n      <th>aspiration<\/th>\n      <th>num-of-doors<\/th>\n      <th>body-style<\/th>\n      <th>drive-wheels<\/th>\n      <th>engine-location<\/th>\n      <th>engine-type<\/th>\n      <th>num-of-cylinders<\/th>\n      <th>fuel-system<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>gas<\/td>\n      <td>std<\/td>\n      <td>two<\/td>\n      <td>convertible<\/td>\n      <td>rwd<\/td>\n      <td>front<\/td>\n      <td>dohc<\/td>\n      <td>four<\/td>\n      <td>mpfi<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>gas<\/td>\n      <td>std<\/td>\n      <td>two<\/td>\n      <td>convertible<\/td>\n      <td>rwd<\/td>\n      <td>front<\/td>\n      <td>dohc<\/td>\n      <td>four<\/td>\n      <td>mpfi<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>gas<\/td>\n      <td>std<\/td>\n      <td>two<\/td>\n      <td>hatchback<\/td>\n      <td>rwd<\/td>\n      <td>front<\/td>\n      <td>ohcv<\/td>\n      <td>six<\/td>\n      <td>mpfi<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>gas<\/td>\n      <td>std<\/td>\n      <td>four<\/td>\n      <td>sedan<\/td>\n      <td>fwd<\/td>\n      <td>front<\/td>\n      <td>ohc<\/td>\n      <td>four<\/td>\n      <td>mpfi<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>gas<\/td>\n      <td>std<\/td>\n      <td>four<\/td>\n      <td>sedan<\/td>\n      <td>4wd<\/td>\n      <td>front<\/td>\n      <td>ohc<\/td>\n      <td>five<\/td>\n      <td>mpfi<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n<\/div>"}, "metadata": {}}], "metadata": {}}, {"source": "We can easily contract factors from the string properties. The method Factorize will be very helpful here. Note that in many cases you will need more advanced ways to handle encoding as it is not trivial", "cell_type": "markdown", "metadata": {}}, {"execution_count": 27, "cell_type": "code", "source": "columns = list(obj_df.columns.values)\n\nfor col in columns:\n    df[col] = df[col].factorize()[0]", "outputs": [], "metadata": {}}, {"execution_count": 28, "cell_type": "code", "source": "df.head()", "outputs": [{"execution_count": 28, "output_type": "execute_result", "data": {"text/plain": "   symboling  normalized-losses  make-id  fuel-type  aspiration  num-of-doors  \\\n0          3                NaN        1          0           0             0   \n1          3                NaN        1          0           0             0   \n2          1                NaN        1          0           0             0   \n3          2              164.0        2          0           0             1   \n4          2              164.0        2          0           0             1   \n\n   body-style  drive-wheels  engine-location  wheel-base   ...     \\\n0           0             0                0        88.6   ...      \n1           0             0                0        88.6   ...      \n2           1             0                0        94.5   ...      \n3           2             1                0        99.8   ...      \n4           2             2                0        99.4   ...      \n\n   engine-size  fuel-system  bore  stroke  compression-ratio  horsepower  \\\n0          130            0  3.47    2.68                9.0       111.0   \n1          130            0  3.47    2.68                9.0       111.0   \n2          152            0  2.68    3.47                9.0       154.0   \n3          109            0  3.19    3.40               10.0       102.0   \n4          136            0  3.19    3.40                8.0       115.0   \n\n   peak-rpm  city-mpg  highway-mpg    price  \n0    5000.0        21           27  13495.0  \n1    5000.0        21           27  16500.0  \n2    5000.0        19           26  16500.0  \n3    5500.0        24           30  13950.0  \n4    5500.0        18           22  17450.0  \n\n[5 rows x 26 columns]", "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>symboling<\/th>\n      <th>normalized-losses<\/th>\n      <th>make-id<\/th>\n      <th>fuel-type<\/th>\n      <th>aspiration<\/th>\n      <th>num-of-doors<\/th>\n      <th>body-style<\/th>\n      <th>drive-wheels<\/th>\n      <th>engine-location<\/th>\n      <th>wheel-base<\/th>\n      <th>...<\/th>\n      <th>engine-size<\/th>\n      <th>fuel-system<\/th>\n      <th>bore<\/th>\n      <th>stroke<\/th>\n      <th>compression-ratio<\/th>\n      <th>horsepower<\/th>\n      <th>peak-rpm<\/th>\n      <th>city-mpg<\/th>\n      <th>highway-mpg<\/th>\n      <th>price<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>3<\/td>\n      <td>NaN<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>88.6<\/td>\n      <td>...<\/td>\n      <td>130<\/td>\n      <td>0<\/td>\n      <td>3.47<\/td>\n      <td>2.68<\/td>\n      <td>9.0<\/td>\n      <td>111.0<\/td>\n      <td>5000.0<\/td>\n      <td>21<\/td>\n      <td>27<\/td>\n      <td>13495.0<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>3<\/td>\n      <td>NaN<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>88.6<\/td>\n      <td>...<\/td>\n      <td>130<\/td>\n      <td>0<\/td>\n      <td>3.47<\/td>\n      <td>2.68<\/td>\n      <td>9.0<\/td>\n      <td>111.0<\/td>\n      <td>5000.0<\/td>\n      <td>21<\/td>\n      <td>27<\/td>\n      <td>16500.0<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>1<\/td>\n      <td>NaN<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>94.5<\/td>\n      <td>...<\/td>\n      <td>152<\/td>\n      <td>0<\/td>\n      <td>2.68<\/td>\n      <td>3.47<\/td>\n      <td>9.0<\/td>\n      <td>154.0<\/td>\n      <td>5000.0<\/td>\n      <td>19<\/td>\n      <td>26<\/td>\n      <td>16500.0<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>2<\/td>\n      <td>164.0<\/td>\n      <td>2<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>2<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>99.8<\/td>\n      <td>...<\/td>\n      <td>109<\/td>\n      <td>0<\/td>\n      <td>3.19<\/td>\n      <td>3.40<\/td>\n      <td>10.0<\/td>\n      <td>102.0<\/td>\n      <td>5500.0<\/td>\n      <td>24<\/td>\n      <td>30<\/td>\n      <td>13950.0<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>2<\/td>\n      <td>164.0<\/td>\n      <td>2<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>2<\/td>\n      <td>2<\/td>\n      <td>0<\/td>\n      <td>99.4<\/td>\n      <td>...<\/td>\n      <td>136<\/td>\n      <td>0<\/td>\n      <td>3.19<\/td>\n      <td>3.40<\/td>\n      <td>8.0<\/td>\n      <td>115.0<\/td>\n      <td>5500.0<\/td>\n      <td>18<\/td>\n      <td>22<\/td>\n      <td>17450.0<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n<p>5 rows \u00c3\u0097 26 columns<\/p>\n<\/div>"}, "metadata": {}}], "metadata": {}}, {"source": "## Handling missing values\n\nDrop missing values", "cell_type": "markdown", "metadata": {}}, {"execution_count": 29, "cell_type": "code", "source": "df.dropna(inplace=True)", "outputs": [], "metadata": {}}, {"source": "# What about method that can handle missing values?", "cell_type": "markdown", "metadata": {}}, {"execution_count": 112, "cell_type": "code", "source": "from sklearn.ensemble import RandomForestRegressor\n\n# Impute our data, then train\nregr = RandomForestRegressor(max_depth=2, random_state=0, n_estimators=100)\nregr = regr.fit(X_train, y_train)", "outputs": [], "metadata": {}}, {"execution_count": 113, "cell_type": "code", "source": "print(regr.feature_importances_)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.98284033e-03\n   2.13071129e-03   0.00000000e+00   1.13071900e-04   0.00000000e+00\n   0.00000000e+00   1.95503695e-03   2.43840993e-02   6.66350065e-02\n   8.45116922e-04   4.19087217e-01   0.00000000e+00   8.27942898e-03\n   6.29080297e-02   1.88050281e-03   6.59173893e-04   2.66393781e-03\n   2.41219578e-03   9.01296480e-03   5.31128256e-03   7.02252467e-02\n   3.19514137e-01]\n"}], "metadata": {}}, {"execution_count": 114, "cell_type": "code", "source": "y_pred_rf = regr.predict(X_test)\nprint(y_pred_rf)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[  9608.86488835   7954.81637273   7289.71930179   9608.86488835\n   7896.59748716   7675.23895293  17404.05444586  17368.14460105\n  12938.11659286   7424.62652701  10014.77191179   7732.78465136\n  10197.90657104  17268.68975989  16614.17518786  16595.73766802\n  27273.60772897   9782.26948604   7289.71930179   7289.71930179\n   7289.71930179   7289.71930179  10197.90657104   7767.37320956\n   7289.71930179  14082.98427302   7313.46841795  17406.15801637\n   7289.71930179  18452.59915327   7289.71930179   9608.86488835\n   9554.74982785  28956.43320006   7289.71930179  14718.52335628\n  17371.4934111    9633.09000416   7289.71930179  18147.11204486\n   7289.71930179   9819.676678    14910.29897524   7289.71930179\n  17368.14460105  17313.37123157  13125.25963552  17194.91248894\n  16614.17518786   7289.71930179   7289.71930179  18452.59915327\n  10228.17543965  16614.17518786   7289.71930179   8532.50495397\n  17516.96615263]\n"}], "metadata": {}}, {"execution_count": 115, "cell_type": "code", "source": "from sklearn.metrics import r2_score\n\nr2_score(y_test, y_pred_rf) ", "outputs": [{"execution_count": 115, "output_type": "execute_result", "data": {"text/plain": "0.81974534463918203"}, "metadata": {}}], "metadata": {}}, {"source": "## Solving the problem with a Neural Network", "cell_type": "markdown", "metadata": {}}, {"execution_count": 36, "cell_type": "code", "source": "from sklearn.neural_network import MLPRegressor\n\nmlp = MLPRegressor(hidden_layer_sizes=(5,),\n                                       activation='relu',\n                                       solver='adam',\n                                       learning_rate='adaptive',\n                                       max_iter=1000,\n                                       learning_rate_init=0.01,\n                                       alpha=0.01)", "outputs": [], "metadata": {}}, {"execution_count": 37, "cell_type": "code", "source": "mlp_regr = mlp.fit(X_train, y_train)", "outputs": [{"output_type": "stream", "name": "stderr", "text": "/home/nbuser/anaconda3_23/lib/python3.4/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n  % (), ConvergenceWarning)\n"}], "metadata": {}}, {"execution_count": 39, "cell_type": "code", "source": "from sklearn.metrics import r2_score\n\ny_pred_mlp = mlp_regr.predict(X_test)\nr2_score(y_test, y_pred_mlp) ", "outputs": [{"execution_count": 39, "output_type": "execute_result", "data": {"text/plain": "0.80011866807608145"}, "metadata": {}}], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.4.5", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}}